{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.patches as patches\n",
    "import pylab\n",
    "import shapely.geometry as geometry\n",
    "import pylab as plt\n",
    "from matplotlib.path import Path\n",
    "import scipy.stats\n",
    "import shapefile\n",
    "from matplotlib.path import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to save the data assimilation estimates and standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the ensemble estimates, interpolated to 5 km resolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = xr.open_dataset('indus_interp51823.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the observations and create a mask of the study domain from them. Use them to create a mask of the study domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = xr.open_dataset('obs_wetsnow_v2.nc')\n",
    "obs_nans = obs.SnowDepth_tavg.max('time')\n",
    "obs_nans = obs_nans.rename({'north_south': 'lat', 'east_west': 'lon'})\n",
    "del obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = xr.open_dataset('obs_wetsnow_v2.nc')\n",
    "obs_mask = ~np.isnan(obs.SnowDepth_tavg.max('time'))\n",
    "def mask(nc): \n",
    "    try: \n",
    "        nc = nc.rename({'lon': 'east_west', 'lat': 'north_south'})\n",
    "    except: \n",
    "        nc = nc\n",
    "    nc = nc.transpose('ensemble', 'time', 'north_south', 'east_west')\n",
    "    nc = nc.where(obs_mask)\n",
    "    try:\n",
    "        nc = nc.__xarray_dataarray_variable__\n",
    "    except:\n",
    "        nc = nc\n",
    "    return nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_all = xr.open_dataset('all_assim_weights_wetsnow_30_May18.nc')\n",
    "normalized_all = normalized_all.__xarray_dataarray_variable__\n",
    "normalized_all = normalized_all.where(~np.isnan(obs_nans))\n",
    "normalized_all = normalized_all.chunk({'lat': 50, 'lon': 50})\n",
    "normalized_all = normalized_all.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_max = xr.open_dataset('max_assim_weights_wetsnow_15June4.nc')\n",
    "normalized_max = normalized_max.__xarray_dataarray_variable__\n",
    "normalized_max = normalized_max.where(~np.isnan(obs_nans))\n",
    "normalized_max = normalized_max.chunk({'lat': 50, 'lon': 50})\n",
    "normalized_max = normalized_max.load()\n",
    "del obs_nans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to save the estimates and standard deviations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_assimilation(ensemble, weights, title, date, var):\n",
    "    #ensemble is the interpolated 5km ensemble \n",
    "    #weights are the weights produced with data assimilation \n",
    "    #title is the naem used in saving \n",
    "    #date is also used in the name\n",
    "    #var is the variable that we want to produce output for \n",
    "    weights['ensemble'] = np.arange(1, 101)\n",
    "    data = ensemble[var]\n",
    "    data = data.load()\n",
    "    print('loaded data')\n",
    "    #data = mask(data)\n",
    "    del ensemble\n",
    "    check = xr.open_dataset('../files_for_pbs/ensemble_final1.nc')\n",
    "    data['time'] = check.time\n",
    "    data = data.load()\n",
    "    del check\n",
    "    data = data.sel(time=slice('2016-10', '2017-09'))\n",
    "    data = data.chunk({'ensemble': 1, 'lat':50, 'lon':50}) \n",
    "    data = data.transpose('time', 'ensemble', 'lat', 'lon')\n",
    "    #creating a weighted average and the posterior estimate \n",
    "    assim = data * weights\n",
    "    ens_sum = assim.sum('ensemble')\n",
    "    del assim \n",
    "    print('loading posterior')\n",
    "    posterior = ens_sum.load()\n",
    "    print('loaded')\n",
    "    del ens_sum\n",
    "    name = var\n",
    "    print('writing ' + name + ' mean')\n",
    "    posterior.to_netcdf(name + '_' +title + '_' + date +'_est.nc')\n",
    "    print('done')\n",
    "    #using the posterior estimate to create the standard deviation \n",
    "    #Calculating the standard deviation using the rule of expectations to calculate variance\n",
    "    e2 =  posterior ** 2\n",
    "    del posterior\n",
    "    ee2 = data**2\n",
    "    print('loading first')\n",
    "    del data \n",
    "    ee2 = ee2 * weights\n",
    "    del weights\n",
    "    ee2 = ee2.sum('ensemble')\n",
    "    print('ee2 done')\n",
    "    std = ee2 - e2\n",
    "    print('std done')\n",
    "    del ee2\n",
    "    del e2\n",
    "    std = np.sqrt(std)\n",
    "    print('loading')\n",
    "    std = std.load()\n",
    "    print('loading done')\n",
    "    print ('writing ' + name + ' std')\n",
    "    std.to_netcdf(name +'_'+title+'_'+date+'_std.nc')\n",
    "    print('done')\n",
    "    del std\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reanalysis-kernel",
   "language": "python",
   "name": "reanalysis-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
